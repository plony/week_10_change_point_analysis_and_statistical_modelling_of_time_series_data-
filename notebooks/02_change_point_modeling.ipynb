{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9ce2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMC Version: 5.25.1\n",
      "ArviZ Version: 0.22.0\n",
      "Data loaded successfully.\n",
      "Sampling from the posterior distribution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [tau]\n",
      ">NUTS: [mu_before, mu_after, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\10academy\\week_10_change_point_analysis_and_statistical_modelling_of_time_series_data\\.venv\\Lib\\site-packages\\ri\n",
       "ch\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d:\\10academy\\week_10_change_point_analysis_and_statistical_modelling_of_time_series_data\\.venv\\Lib\\site-packages\\ri\n",
       "ch\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Imports and Data Loading\n",
    "# This cell sets up the environment and loads the necessary data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "print(f\"PyMC Version: {pm.__version__}\")\n",
    "print(f\"ArviZ Version: {az.__version__}\")\n",
    "\n",
    "# Load the cleaned data and events data from Task 1\n",
    "try:\n",
    "    brent_prices_df = pd.read_csv('../data/processed/brent_prices_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "    events_df = pd.read_csv('../data/processed/geopolitical_events.csv', parse_dates=['event_date'])\n",
    "    \n",
    "    # Extract the prices for modeling\n",
    "    prices = brent_prices_df['Price'].values\n",
    "    \n",
    "    # The size of our dataset\n",
    "    N = prices.shape[0]\n",
    "    \n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Ensure that the data ingestion and event research scripts from Task 1 have been run.\")\n",
    "    print(\"Files 'brent_prices_cleaned.csv' and 'geopolitical_events.csv' are required in '../data/processed/'.\")\n",
    "\n",
    "# Cell 2: Define and Run the Change Point Model\n",
    "# This model assumes the mean of the prices changes at a specific, unknown point in time.\n",
    "# The code has been updated to use the correct `sigma` keyword for PyMC v4+.\n",
    "\n",
    "with pm.Model() as oil_price_model:\n",
    "    \n",
    "    # 1. Define the switch point (tau)\n",
    "    # A discrete uniform prior over all possible days in the dataset.\n",
    "    # We are modeling the *index* of the change point.\n",
    "    tau = pm.DiscreteUniform('tau', lower=0, upper=N)\n",
    "    \n",
    "    # 2. Define the \"Before\" and \"After\" parameters (mean and standard deviation)\n",
    "    # The mean prices before and after the change point\n",
    "    mu_before = pm.Normal('mu_before', mu=prices.mean(), sigma=5)\n",
    "    mu_after = pm.Normal('mu_after', mu=prices.mean(), sigma=5)\n",
    "    \n",
    "    # The standard deviation (volatility) of the prices\n",
    "    # Use an Exponential distribution for standard deviation as it must be positive.\n",
    "    sigma = pm.Exponential('sigma', lam=1)\n",
    "    \n",
    "    # 3. Use a switch function to select the correct mean based on tau\n",
    "    # The `pm.math.switch` function will select mu_before if the index is < tau,\n",
    "    # and mu_after if the index is >= tau.\n",
    "    mu = pm.math.switch(tau >= np.arange(N), mu_before, mu_after)\n",
    "    \n",
    "    # 4. Define the likelihood: connect the model to the data\n",
    "    # The observed prices are assumed to be normally distributed around the mean.\n",
    "    observation = pm.Normal('observation', mu=mu, sigma=sigma, observed=prices)\n",
    "    \n",
    "    # 5. Run the sampler (MCMC simulation)\n",
    "    # This will sample to find the posterior distributions of your parameters.\n",
    "    # It might take a few minutes to run.\n",
    "    print(\"Sampling from the posterior distribution...\")\n",
    "    idata = pm.sample(draws=2000, tune=1000, cores=2, return_inferencedata=True)\n",
    "\n",
    "# Cell 3: Interpreting the Model Output\n",
    "# This cell visualizes the results of the MCMC sampling.\n",
    "\n",
    "# Check for convergence and inspect the model\n",
    "print(\"\\nModel Summary:\")\n",
    "print(az.summary(idata, round_to=2))\n",
    "\n",
    "# Plot the trace to check for sampling convergence\n",
    "az.plot_trace(idata)\n",
    "plt.show()\n",
    "\n",
    "# Identify the change point (tau) by plotting its posterior distribution\n",
    "tau_samples = idata.posterior['tau'].values.flatten()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(tau_samples, bins=50)\n",
    "plt.title('Posterior Distribution of the Change Point (tau)')\n",
    "plt.xlabel('Day Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Get the most probable change point date\n",
    "most_probable_tau = pd.Series(tau_samples).mode()[0]\n",
    "change_point_date = brent_prices_df.index[most_probable_tau]\n",
    "print(f\"The most probable change point occurred on: {change_point_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Visualize the impact (before vs. after prices)\n",
    "az.plot_posterior(idata, var_names=['mu_before', 'mu_after'])\n",
    "plt.show()\n",
    "\n",
    "# Associate with events\n",
    "# Compare the `change_point_date` with the `events_df` from your Task 1 research\n",
    "# to formulate hypotheses about the cause of the change.\n",
    "print(\"\\nMost probable change point date:\")\n",
    "print(change_point_date)\n",
    "print(\"\\nCompare this with your researched events to associate causes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
